{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec4a938",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# IAM Entitlement Analysis Notebook\\n\",\n",
    "    \"## CloudGuardStack - Interactive IAM Security Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import required libraries\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from IPython.display import display, Markdown\\n\",\n",
    "    \"import plotly.express as px\\n\",\n",
    "    \"import plotly.graph_objects as go\\n\",\n",
    "    \"from plotly.subplots import make_subplots\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set up plotting style\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"%matplotlib inline\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load Entitlement Report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load the entitlement report\\n\",\n",
    "    \"with open('../entitlement_report.json', 'r') as f:\\n\",\n",
    "    \"    report = json.load(f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"display(Markdown(f\\\"### Scan Overview\\\"))\\n\",\n",
    "    \"display(Markdown(f\\\"- **Scan Time**: {report['scan_metadata']['scan_time']}\\\"))\\n\",\n",
    "    \"display(Markdown(f\\\"- **Account ID**: {report['scan_metadata']['account_id']}\\\"))\\n\",\n",
    "    \"display(Markdown(f\\\"- **Entities Scanned**: {report['scan_metadata']['entities_scanned']}\\\"))\\n\",\n",
    "    \"display(Markdown(f\\\"- **Total Findings**: {report['scan_metadata']['total_findings']}\\\"))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Risk Score Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create risk score DataFrame\\n\",\n",
    "    \"risk_df = pd.DataFrame.from_dict(report['risk_scores'], orient='index', columns=['risk_score'])\\n\",\n",
    "    \"risk_df = risk_df.sort_values('risk_score', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Top 10 Riskiest Entities:\\\")\\n\",\n",
    "    \"display(risk_df.head(10))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot risk distribution\\n\",\n",
    "    \"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Risk score distribution\\n\",\n",
    "    \"ax1.hist(risk_df['risk_score'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\\n\",\n",
    "    \"ax1.set_title('Distribution of Risk Scores')\\n\",\n",
    "    \"ax1.set_xlabel('Risk Score')\\n\",\n",
    "    \"ax1.set_ylabel('Number of Entities')\\n\",\n",
    "    \"ax1.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Top entities by risk\\n\",\n",
    "    \"top_10 = risk_df.head(10)\\n\",\n",
    "    \"ax2.barh(top_10.index, top_10['risk_score'], color='coral', alpha=0.7)\\n\",\n",
    "    \"ax2.set_title('Top 10 Riskiest Entities')\\n\",\n",
    "    \"ax2.set_xlabel('Risk Score')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Finding Type Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze finding types\\n\",\n",
    "    \"findings_data = []\\n\",\n",
    "    \"for finding_type, items in report['findings'].items():\\n\",\n",
    "    \"    for item in items:\\n\",\n",
    "    \"        findings_data.append({\\n\",\n",
    "    \"            'finding_type': finding_type,\\n\",\n",
    "    \"            'entity_name': item.get('entity_name', 'unknown'),\\n\",\n",
    "    \"            'risk_level': item.get('risk_level', 'MEDIUM')\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"\\n\",\n",
    "    \"findings_df = pd.DataFrame(findings_data)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Finding type counts\\n\",\n",
    "    \"finding_counts = findings_df['finding_type'].value_counts()\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Finding types pie chart\\n\",\n",
    "    \"ax1.pie(finding_counts.values, labels=finding_counts.index, autopct='%1.1f%%', startangle=90)\\n\",\n",
    "    \"ax1.set_title('Finding Types Distribution')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Risk level by finding type\\n\",\n",
    "    \"risk_by_type = findings_df.groupby(['finding_type', 'risk_level']).size().unstack(fill_value=0)\\n\",\n",
    "    \"risk_by_type.plot(kind='bar', ax=ax2, stacked=True)\\n\",\n",
    "    \"ax2.set_title('Risk Levels by Finding Type')\\n\",\n",
    "    \"ax2.set_xlabel('Finding Type')\\n\",\n",
    "    \"ax2.set_ylabel('Count')\\n\",\n",
    "    \"ax2.legend(title='Risk Level')\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Interactive Visualization with Plotly\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create interactive risk score visualization\\n\",\n",
    "    \"fig = go.Figure()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add risk scores as bars\\n\",\n",
    "    \"fig.add_trace(go.Bar(\\n\",\n",
    "    \"    x=risk_df.index[:15],  # Top 15 entities\\n\",\n",
    "    \"    y=risk_df['risk_score'][:15],\\n\",\n",
    "    \"    marker_color=['#FF6B6B' if score >= 80 else '#FFA726' if score >= 60 else '#FFE082' for score in risk_df['risk_score'][:15]]\\n\",\n",
    "    \"))\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig.update_layout(\\n\",\n",
    "    \"    title='Top 15 IAM Entities by Risk Score',\\n\",\n",
    "    \"    xaxis_title='IAM Entities',\\n\",\n",
    "    \"    yaxis_title='Risk Score',\\n\",\n",
    "    \"    showlegend=False,\\n\",\n",
    "    \"    height=500\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Remediation Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze remediation suggestions\\n\",\n",
    "    \"remediation_df = pd.DataFrame(report['remediation_suggestions'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not remediation_df.empty:\\n\",\n",
    "    \"    print(\\\"Remediation Priority Summary:\\\")\\n\",\n",
    "    \"    priority_summary = remediation_df['priority'].value_counts()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    fig = px.pie(\\n\",\n",
    "    \"        values=priority_summary.values,\\n\",\n",
    "    \"        names=priority_summary.index,\\n\",\n",
    "    \"        title='Remediation Priority Distribution',\\n\",\n",
    "    \"        color=priority_summary.index,\\n\",\n",
    "    \"        color_discrete_map={\\n\",\n",
    "    \"            'CRITICAL': '#FF6B6B',\\n\",\n",
    "    \"            'HIGH': '#FFA726',\\n\",\n",
    "    \"            'MEDIUM': '#FFE082',\\n\",\n",
    "    \"            'LOW': '#C8E6C9'\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    fig.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Display high priority remediations\\n\",\n",
    "    \"    high_priority = remediation_df[remediation_df['priority'].isin(['CRITICAL', 'HIGH'])]\\n\",\n",
    "    \"    if not high_priority.empty:\\n\",\n",
    "    \"        display(Markdown(\\\"### High Priority Remediation Actions\\\"))\\n\",\n",
    "    \"        for _, row in high_priority.iterrows():\\n\",\n",
    "    \"            display(Markdown(f\\\"**{row['entity']}** - {row['suggestion']}\\\"))\\n\",\n",
    "    \"            display(Markdown(f\\\"*Steps:* {', '.join(row['steps'])}\\\"))\\n\",\n",
    "    \"            display(Markdown(\\\"---\\\"))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Export Analysis Results\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate summary report\\n\",\n",
    "    \"summary_data = {\\n\",\n",
    "    \"    'total_entities': report['scan_metadata']['entities_scanned'],\\n\",\n",
    "    \"    'total_findings': report['scan_metadata']['total_findings'],\\n\",\n",
    "    \"    'critical_findings': report['summary']['critical_findings'],\\n\",\n",
    "    \"    'high_findings': report['summary']['high_findings'],\\n\",\n",
    "    \"    'medium_findings': report['summary']['medium_findings'],\\n\",\n",
    "    \"    'low_findings': report['summary']['low_findings'],\\n\",\n",
    "    \"    'average_risk_score': risk_df['risk_score'].mean(),\\n\",\n",
    "    \"    'max_risk_score': risk_df['risk_score'].max()\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"summary_df = pd.DataFrame([summary_data])\\n\",\n",
    "    \"display(Markdown(\\\"### Executive Summary\\\"))\\n\",\n",
    "    \"display(summary_df.T.rename(columns={0: 'Metrics'}))\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
